---
layout: default
title: Least Angle Regression
tags: [Machine Learning]
---

<h2>背景知识</h2>
<p>
最小角回归和模型选择比较像，是一个逐步的过程，每一步都选择一个相关性最大的特征，总的运算步数只和特征的数目有关，和训练集的大小无关。最小角回归训练时的输入为特征矩阵 $$$ X = \{X_1, X_2,..., X_P\} $$$，和期输出向量$$$ Y = \{y_1, y_2,..., y_N \} $$$，$$$X_i$$$ 是长度为$$$N$$$的矩阵，$$$N$$$表示训练集的大小，$$$P$$$则是特征的数目。还有一点需要注意的是，向量$$$X_i$$$ 和 $$$Y$$$ 都是正则化之后的向量，即它们的元素的均值为0，且每个向量的长度都是1，这样做的目的是为了后面计算相关性以及角度的方便。
</p>

<h3>相关性</h3>
<p>
相关性一般是用来衡量两个向量之间的相关程度，通常采用相关性公式进行计算，其中A，B为向量：
</p>

$$ \begin{eqnarray*}
	corr &=& \frac{Cov(A,B)}{\sqrt{Var(A)Var(B)}} \\
		 &=& \frac{E[(A-\bar{A})(B-\bar{B})]}{\sqrt{E[(A-\bar{A})^2]E[(B-\bar{B})^2]}}
\end{eqnarray*} $$

<p>
corr的绝对值越大，表示A，B的相关性越大，反之则越小。corr的符号则表示这两个向量是正相关还是负相关。由于最小回归的训练数据是经过正则化的，即$$$ \bar{A} = \bar{B} = 0 $$$，$$$|A| = |B| = 1$$$，所以上面的计算公式可以进行简化。
</p>

$$ \begin{eqnarray*}
	corr &=& \frac{E(AB)}{\sqrt{E(A^2)E(B^2)}} \\
		 &=& \frac{E(AB)}{\sqrt{1*1}} \\
		 &=& E(AB)
\end{eqnarray*} $$

<p>
在最小角回归中，$$$E(AB) = \frac{AB}{n} $$$，其中n是向量A或B中元素的个数，因而n是定值，所以为了方便计算，在计算向量的相关性时，我们只需要计算$$$ AB $$$即可。为了计算每个特征和期望输出的相关性，我们需要计算每个$$$X_i$$$ 与 $$$Y$$$的相关性，这种情况下，我们可以采用矩阵和向量的乘法来进行运算，这里X是$$$N \times P$$$的特征矩阵，Y则是大小为N的期望输出向量。
</p>

$$ \begin{eqnarray*}
	Corr &=& X^T Y
\end{eqnarray*} $$

<p>
这里的$$$Corr$$$是一个大小为P的向量，且 $$$Corr[i]$$$表示特征$$$X_i$$$与$$$Y$$$的相关性。
</p>

<h2>参数选择过程</h2>
<p>
在最小角回归中，参数选择的准则就是相关性，每次都选择和期望输出相关性最大的特征，即$$$max(|Corr[i]|)$$$。
</p>

<h3>前进路径</h3>
<p>
在我们的特征矩阵中，共有P个特征向量，每个向量都是N维的，期望输出矩阵Y也是N维的，因此我们可以将这些特征向量以及期望输出向量看作是N维空间中的点，而我们的目的就是在这个空间中找到一条从原点到Y的路径。需要满足的条件就是这条路径可以使用特征矩阵的线性组来合表示，而这些特征矩阵的系数就是线性回归的权重向量。
</p>

<p>
$$$ \hat{u}_A$$$ 表示从原点出发的一条路径，其初始值为$$$ \vec{0}$$$，我们的目的是在经过若干步之后，使得$$$ \hat{u}_A = Y $$$。每一步中，$$$\hat{u}_A$$$的增量为 $$$\hat{\gamma}u_A$$$，其中$$$u_A$$$ 为单位向量，它指明了 $$$\hat{u}_A$$$ 的前进方向，$$$\hat{\gamma}$$$ 则是前进的距离。
</p>

<h3>前进方向</h3>
<p>
在最小角回归的计算过程中，每一步都会选择一个和期望输出最相关的特征$$$X_i$$$，可以用矩阵 $$$ X_A$$$ 表示被选中的特征的集合，$$$ X_A = (...,s_jX_j,...)$$$，$$$s_j$$$ 表示$$$X_j$$$ 与期望输出相关性的符号。选择完变量之后，就是计算前进方向。由于是最小角回归，所以其选择方向的策略就是选择等分$$$X_A$$$中所有向量的角的方向，也就是说$$$u_A$$$和$$$X_A$$$中所有的列向量所成的角相等，那么只需要保证他们之间的$$$cos$$$值相等即可。因为$$$ cos(A,B) = \frac{AB}{|A||B|}$$$，而所有的$$$ |s_jX_j| = 1$$$， 因此为了保证所有的$$$ cos(s_jX_j, u_A) $$$都相等，只需要保证所有的$$$(s_jX_j)u_A $$$ 都相等即可，也就是说要保证$$$ X_A^Tu_A = A_A1_A$$$，其中$$$A_A$$$为实数。我们知道方阵与其逆矩阵的乘积为单位矩阵，我们可以利用这个性质来构造$$$u_A$$$，然而我们无法保证$$$X_A^T$$$是方阵，但我们可以保证$$$X_A^T X_A$$$为方阵，因此我们可以令 $$$u_A = X_A(X_A^T X_A)^{-1}A_A1_A$$$，此时$$$X_A^T u_A = A_A1_A$$$。同时，因为$$$u_A$$$是单位向量，因此 $$$ |u_A| = 1$$$，也就是说 $$$ u_A^T u_A = 1$$$，由此可以得到 $$$ A_A = (1_A^T (X_A^T X_A)^{-1} 1_A)^{0.5}$$$。至此，我们得到以下公式:

$$ \begin{eqnarray*}
	G_A &=& X_A^T X_A \\
	A_A &=& (1_A^T G_A^{-1} 1_A)^{0.5} \\
	u_A &=& X_A G_A^{-1} A_A 1_A

\end{eqnarray*} $$
</p>

<h3>前进距离</h3>
<p>

</p>
